**ZStack 是一个开源的 IaaS(Infrustruction as a service) 软件,旨在全部使用 API 实现自动化数据中心、管理计算、存储和网络。**
# 伸缩性

- 异步架构

  传统的Iaas采用同步架构，线程池为每个任务提供线程，线程只有在前一个任务完成之后才能为下一个任务服务。例如创建虚拟机，通常的执行路径为”identity service-->scheduler-->image service-->storage service-->network service-->hypervisor”，它的每一环节都要一定的耗时，大批量任务执行时，延迟效应就更明显，最后就可能出现任务失败。<br/>
  ZStack 99%的任务都是异步执行的，这是使它单个节点能够管理几十万的物理机、几百万的虚拟机和处理上万并发任务的关键。
  
  ZStack 的异步架构由三部分组成：异步消息、异步方法和异步HTTP调用。<br/>
  异步消息：<br/>
  ZStack 使用 RabbitMQ 作为连接各种服务的消息总线。当一个服务调用另一个服务的时候，源服务向目的服务发送一个消息同时注册回调函数，然后立即返回。当目的服务完成任务后，它响应触发源服务注册的回调函数来通知结果。<br/>
  异步方法：<br/>
  在ZStack 中，作为一等公民类型的服务通过异步消息进行交互。对于服务内部，一系列的互相关联的组件、插件是通过异步方法调用来交互的。<br/>
  异步 HTTP 调用：<br/>
  ZStack 使用几个代理来管理外部系统，例如 KVM 主机、控制台代理和虚拟路由等。它们都是以 Python CherryPy 为基础构建的轻量级 Web 服务。ZStack 可以进行双向通讯，它在每次请求的时候把回调 URL 放入 HTTP 头部，代理可以在任务完成的时候把响应通过 URL 发送给调用方。<br/>
  ![异步架构图](http://zstack.org/images/blogs/scalability/2.png)
--------
- 无状态服务

  当用户想要一个高可用的生产环境或者处理海量并发负载时，需要进行横向扩展，即增加节点，这时就需要一个可靠的分发系统。ZStack 构建了一个由无状态服务组成的无状态分发系统。
  
  什么是状态？当系统中存在多余一个服务实例的时候，资源会被划分为不同的实例。例如，假如有10,000个虚拟机和两个虚拟机服务实例，每个实例管理5000个虚拟机，像 ”哪个服务实例正在管理什么资源“ 的认知，正是我们正在谈论的状态。当服务实例的数目发生变化的时候，服务需要交换状态，这就成了系统可扩充性的瓶颈。有了无状态服务，请求方不再需要询问向哪里发送请求，当新的服务示例加入到旧的示例中时，服务不再需要交换状态。
  
  每个 ZStack 的服务都是无状态的。 ZStack 把所有的服务都封装进一个叫做管理节点的单一进程中，使得部署和管理服务极其简单。一个管理节点是一个功能完备的ZStack软件。由于包含了无状态服务，管理节点没有共享状态，但是有心跳记录，以及一致性哈希算法环（consistent hashing ring）。心跳用来监测管理节点的健康状况，一旦一个管理节点停止更新它的管理节点一段时间后，其他的管理节点就会将它删除并接管它管理的资源。
  
  具体到 ZStack 的业务逻辑，实现无状态服务的核心技术是[一致哈希算法](http://www.tom-e-white.com/2007/11/consistent-hashing.html)。当系统启动的时候，每个管理节点都会被分配一个用来配合服务名称在消息总线上注册一个服队列的版本4 UUID（Version 4 UUID）。资源，如主机，容量，虚拟机，也是通过  UUID 来标识的。消息，常常和资源相关联，是在服务间传递的。在发送消息之前，发送者必须选择基于资源的UUID的接收者服务。
  
  每个管理节点都维护一个系统所有包含 UUID 的所有管理节点的环的复制。当一个管理节点加入或离开时，生命周期事件将或通过消息总线向其他所有的节点广播，使其他节点扩展或者压缩他们的环以适应当前的系统状态。当发送的时候，发送者的服务方将会使用资源的 UUID 哈希出目的管理节点的 UUID。在一个稳定的环中，拥有相同 UUID 的资源时可以经常被路由到相同的服务，这是 ZStack 无锁架构的基础。由于一致哈希环的存在，发送方不必知道哪个服务实例将要处理这个消息，这个实例将会被哈希出来。服务不必维护和交换他们管理这的资源的信息，他们只需要处理接收到的消息，因为一致哈希环能够确保消息能够找到正确的服务实例。
  ![一致哈希环](http://zstack.org/images/blogs/scalability/stateless-service7.png)
  
  对于 API 消息来说，有一个特殊的处理，它们总是发送一个已知的服务 ID api.portal 。在消息总线上，一个叫做 zstack.message.api.portal 的全局队列，它被所有的管理节点 API 服务所共享，带有服务 ID api.portal 的消息将会自动负载均衡到其中的一个API服务，这个服务还会使用一致性哈希环将消息路由到正确的目的服务。通过这种做法，ZStack 隐藏了来自 API 客户端消息路由转发的细节，并简化了编写一个ZStack API 客户端的工作。
-------
- 无锁架构
  一致哈希算法能保证所有发往相同资源的消息被相同的服务实例所处理，它是无锁架构的基础。这种聚集消息到特定节点的方法，降低了在多线程环境下的同步和并行分发系统的复杂性。
  
  ZStack 中的任务是由消息驱动的，聚集消息也使得相应的任务可以在相同的节点上执行，这样就减轻了经典线程池的并发编程问题的挑战。为了避免锁竞争，ZStack 使用工作队列而不是锁和信号量。同步任务维护在基于工作队列的内存中，可以一个一个的执行。并行任务可以在定义的并行级别执行，它们由拥有并发级别的工作队列维护。工作队列可以同时执行同步化的和并行的任务。如果并行级别为1，那么队列就是同步化的；如果并行级别大于1，那么队列是并行的；如果并行级别为0，那么队列就是无限并行的。
  
  ZStack 中有两种类型的基于内存的工作队列。一种是同步工作队列，任务返回后才被认为完成。另一种是异步工作队列，其中任务只有在其触发完成通知后才被认为是完成。
  
  基于内存的工作队列即快又简单，可以解决 99% 的在单个管理节点的同步和并行需求。然而，创建资源相关的任务可能需要在多个管理节点之间同步。所以 ZStack使用一个基于数据库的工作队列，其中不同管理节点的任务能够全局的进行同步。数据库工作队列只有同步的形式，也就是说，下一个任务只有在前一个任务触发完成通知之后才能执行。同时因为任务是存放在数据库中的，数据库工作队列会比较慢，幸运的是只有创建虚拟路由才会需要它。
  
  尽管基于无锁队列架构的队列 99.99% 的时间都能正确处理同步任务，但仍然存在一致哈希算法产生的竞态条件：一个新加入的节点由于一致哈希环的结果将会从相邻节点分担一部分的工作量。
  ![竟态条件](http://zstack.org/images/blogs/scalability/lock-free6.png)
  
  ZStack 没有涉及复杂的分布式协作软件，尽可能地在争用条件下的屏蔽任务中配合提升性能。

------

# 插件架构

- 微服务

  为了应对维护务经常面对的诸如重要的操作的开销、重复的努力、可测试性等问题，以及获得代码解耦以及易扩展的好处，ZStack 引入了微服务，它把所有的服务都包含在一个叫做管理节点的单一进程中，构造了一个进程内微内核架构。微内核可以帮助一个糟糕的软件系统从一个紧密的网络拓扑架构转变为一个松耦合的星状拓扑架构。

  ZStack 的单进程微服务架构除了微服务带来的解耦架构等好处外，还有：
```
    * 简明的依赖。因为只有单一进程，升级或者变更支持库就像对单个二进制应用程序那样简单。
    * 高可用、负载均衡和监控。
    * 中心化的配置。单个节点中，所有服务共享同一个配置文件。
    * 易部署、维护、升级和横向扩展。
    * 支持插件功能。
```
  
- 通用的插件系统
  
  由于Iaas无法预测用户会使用哪些额外的功能，所以 ZStack 提供了一个不会影响核心功能稳定性的插件机制。
  
  贯穿 ZStack 组件的一个重要设计理念是: 每个组件应该被设计为最小关联、独立的以及可被其他组件所忽略的。它提供以下几种插件形式，在保证架构松耦合的同时较容易的添加特性以组成一个完整的云系统。<br/>
  策略模式插件: ZStack 把云资源抽象为 hypervisors、primary storage、backup storage、L2 networks、L3 networks 等等。每种资源都有一个独立的插件作为参考驱动。开发者只需实现三种组件几个增加一个新的驱动，它们分别是类型、工厂、具体的资源实现。<br/>
  观察者模式插件: 它允许对以存在的 ZStack 功能进行扩展。它的关键之处是扩展点，这些点允许插件中的代码片段可以在代码流执行期间被调用。<br/>
  进程外服务插件:ZStack有一个定义良好的消息规范，进程外服务可以用任何语言编写，只要它能够通过 RabbitMQ 进行通信。ZStack Web UI 就是一个很好的例子，它使用 Python 语言编写，通过 RabbitMQ 与 ZStack 进行通信。 ZStack 有一个叫做 canonical event 的机制，它把内部的一些事件暴露出来，例如 VM created, VM stopped, volume created 等等。
  
  ![进程外服务插件](http://zstack.org/images/blogs/scalability/plugin3.png)

- 标签系统

  随着云上面的资源的增长,用户们可能想要有一种可以组合相似资源的高可读性标签的的方法,例如使用 "web-tier-vm" 代表所有 web 服务器的虚拟机。ZStack 中的标签不止能帮助用户对资源进行聚合，而且还能控制软件的行为。ZStack 有一套完整的定义目录、表格和标签用途的规范。除了用户标签也能创建它们自己的标签，可以记录已存在资源的元数据可扩展属性。

  在 ZStack 中，标签上是是包含了与资源相关联的信息片段。主要由以下字段组成：
  
```
    * uuid		标签的 UUID
    * resourceUuid	与标签相关联的资源的 UUID
    * resourceType	与标签相关联的资源类型
    * tag			      包含有意义的信息字符串
    * type		      标签类型：System 或 User
```
    
  ZStack 与其他 IaaS 软件标签的主要不同之处在于：ZStack 把标签分成了两大类：User 和 System。
