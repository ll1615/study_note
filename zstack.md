**ZStack 是一个开源的 IaaS(Infrustruction as a service) 软件,旨在全部使用 API 实现自动化数据中心、管理计算、存储和网络。**
# 伸缩性

- 异步架构

  传统的Iaas采用同步架构，线程池为每个任务提供线程，线程只有在前一个任务完成之后才能为下一个任务服务。例如创建虚拟机，通常的执行路径为”identity service-->scheduler-->image service-->storage service-->network service-->hypervisor”，它的每一环节都要一定的耗时，大批量任务执行时，延迟效应就更明显，最后就可能出现任务失败。<br/>
  ZStack 99%的任务都是异步执行的，这是使它单个节点能够管理几十万的物理机、几百万的虚拟机和处理上万并发任务的关键。
  
  ZStack 的异步架构由三部分组成：异步消息、异步方法和异步HTTP调用。<br/>
  异步消息：<br/>
  ZStack 使用 RabbitMQ 作为连接各种服务的消息总线。当一个服务调用另一个服务的时候，源服务向目的服务发送一个消息同时注册回调函数，然后立即返回。当目的服务完成任务后，它响应触发源服务注册的回调函数来通知结果。<br/>
  异步方法：<br/>
  在ZStack 中，作为一等公民类型的服务通过异步消息进行交互。对于服务内部，一系列的互相关联的组件、插件是通过异步方法调用来交互的。<br/>
  异步 HTTP 调用：<br/>
  ZStack 使用几个代理来管理外部系统，例如 KVM 主机、控制台代理和虚拟路由等。它们都是以 Python CherryPy 为基础构建的轻量级 Web 服务。ZStack 可以进行双向通讯，它在每次请求的时候把回调 URL 放入 HTTP 头部，代理可以在任务完成的时候把响应通过 URL 发送给调用方。<br/>
  ![异步架构图](http://zstack.org/images/blogs/scalability/2.png)
--------
- 无状态服务

  当用户想要一个高可用的生产环境或者处理海量并发负载时，需要进行横向扩展，即增加节点，这时就需要一个可靠的分发系统。ZStack 构建了一个由无状态服务组成的无状态分发系统。
  
  什么是状态？当系统中存在多余一个服务实例的时候，资源会被划分为不同的实例。例如，假如有10,000个虚拟机和两个虚拟机服务实例，每个实例管理5000个虚拟机，像 ”哪个服务实例正在管理什么资源“ 的认知，正是我们正在谈论的状态。当服务实例的数目发生变化的时候，服务需要交换状态，这就成了系统可扩充性的瓶颈。有了无状态服务，请求方不再需要询问向哪里发送请求，当新的服务示例加入到旧的示例中时，服务不再需要交换状态。
  
  每个 ZStack 的服务都是无状态的。 ZStack 把所有的服务都封装进一个叫做管理节点的单一进程中，使得部署和管理服务极其简单。一个管理节点是一个功能完备的ZStack软件。由于包含了无状态服务，管理节点没有共享状态，但是有心跳记录，以及一致性哈希算法环（consistent hashing ring）。心跳用来监测管理节点的健康状况，一旦一个管理节点停止更新它的管理节点一段时间后，其他的管理节点就会将它删除并接管它管理的资源。
  
  具体到 ZStack 的业务逻辑，实现无状态服务的核心技术是[一致哈希算法](http://www.tom-e-white.com/2007/11/consistent-hashing.html)。当系统启动的时候，每个管理节点都会被分配一个用来配合服务名称在消息总线上注册一个服队列的版本4 UUID（Version 4 UUID）。资源，如主机，容量，虚拟机，也是通过  UUID 来标识的。消息，常常和资源相关联，是在服务间传递的。在发送消息之前，发送者必须选择基于资源的UUID的接收者服务。
  
  每个管理节点都维护一个系统所有包含 UUID 的所有管理节点的环的复制。当一个管理节点加入或离开时，生命周期事件将或通过消息总线向其他所有的节点广播，使其他节点扩展或者压缩他们的环以适应当前的系统状态。当发送的时候，发送者的服务方将会使用资源的 UUID 哈希出目的管理节点的 UUID。在一个稳定的环中，拥有相同 UUID 的资源时可以经常被路由到相同的服务，这是 ZStack 无锁架构的基础。由于一致哈希环的存在，发送方不必知道哪个服务实例将要处理这个消息，这个实例将会被哈希出来。服务不必维护和交换他们管理这的资源的信息，他们只需要处理接收到的消息，因为一致哈希环能够确保消息能够找到正确的服务实例。
  ![一致哈希环](http://zstack.org/images/blogs/scalability/stateless-service7.png)
  
  对于 API 消息来说，有一个特殊的处理，它们总是发送一个已知的服务 ID api.portal 。在消息总线上，一个叫做 zstack.message.api.portal 的全局队列，它被所有的管理节点 API 服务所共享，带有服务 ID api.portal 的消息将会自动负载均衡到其中的一个API服务，这个服务还会使用一致性哈希环将消息路由到正确的目的服务。通过这种做法，ZStack 隐藏了来自 API 客户端消息路由转发的细节，并简化了编写一个ZStack API 客户端的工作。
-------
- 无锁架构
  一致哈希算法能保证所有发往相同资源的消息被相同的服务实例所处理，它是无锁架构的基础。这种聚集消息到特定节点的方法，降低了在多线程环境下的同步和并行分发系统的复杂性。
  
  ZStack 中的任务是由消息驱动的，聚集消息也使得相应的任务可以在相同的节点上执行，这样就减轻了经典线程池的并发编程问题的挑战。为了避免锁竞争，ZStack 使用工作队列而不是锁和信号量。同步任务维护在基于工作队列的内存中，可以一个一个的执行。并行任务可以在定义的并行级别执行，它们由拥有并发级别的工作队列维护。工作队列可以同时执行同步化的和并行的任务。如果并行级别为1，那么队列就是同步化的；如果并行级别大于1，那么队列是并行的；如果并行级别为0，那么队列就是无限并行的。
  
  ZStack 中有两种类型的基于内存的工作队列。一种是同步工作队列，任务返回后才被认为完成。另一种是异步工作队列，其中任务只有在其触发完成通知后才被认为是完成。
  
  基于内存的工作队列即快又简单，可以解决 99% 的在单个管理节点的同步和并行需求。然而，创建资源相关的任务可能需要在多个管理节点之间同步。所以 ZStack使用一个基于数据库的工作队列，其中不同管理节点的任务能够全局的进行同步。数据库工作队列只有同步的形式，也就是说，下一个任务只有在前一个任务触发完成通知之后才能执行。同时因为任务是存放在数据库中的，数据库工作队列会比较慢，幸运的是只有创建虚拟路由才会需要它。
  
  尽管基于无锁队列架构的队列 99.99% 的时间都能正确处理同步任务，但仍然存在一致哈希算法产生的竞态条件：一个新加入的节点由于一致哈希环的结果将会从相邻节点分担一部分的工作量。
  ![竟态条件](http://zstack.org/images/blogs/scalability/lock-free6.png)
  
  ZStack 没有涉及复杂的分布式协作软件，尽可能地在争用条件下的屏蔽任务中配合提升性能。

------

# 插件架构

- 微服务

  为了应对维护务经常面对的诸如重要的操作的开销、重复的努力、可测试性等问题，以及获得代码解耦以及易扩展的好处，ZStack 引入了微服务，它把所有的服务都包含在一个叫做管理节点的单一进程中，构造了一个进程内微内核架构。微内核可以帮助一个糟糕的软件系统从一个紧密的网络拓扑架构转变为一个松耦合的星状拓扑架构。

  ZStack 的单进程微服务架构除了微服务带来的解耦架构等好处外，还有：
```
    * 简明的依赖。因为只有单一进程，升级或者变更支持库就像对单个二进制应用程序那样简单。
    * 高可用、负载均衡和监控。
    * 中心化的配置。单个节点中，所有服务共享同一个配置文件。
    * 易部署、维护、升级和横向扩展。
    * 支持插件功能。
```
  
- 通用的插件系统
  
  由于Iaas无法预测用户会使用哪些额外的功能，所以 ZStack 提供了一个不会影响核心功能稳定性的插件机制。
  
  贯穿 ZStack 组件的一个重要设计理念是: 每个组件应该被设计为最小关联、独立的以及可被其他组件所忽略的。它提供以下几种插件形式，在保证架构松耦合的同时较容易的添加特性以组成一个完整的云系统。<br/>
  策略模式插件: ZStack 把云资源抽象为 hypervisors、primary storage、backup storage、L2 networks、L3 networks 等等。每种资源都有一个独立的插件作为参考驱动。开发者只需实现三种组件几个增加一个新的驱动，它们分别是类型、工厂、具体的资源实现。<br/>
  观察者模式插件: 它允许对以存在的 ZStack 功能进行扩展。它的关键之处是扩展点，这些点允许插件中的代码片段可以在代码流执行期间被调用。<br/>
  进程外服务插件:ZStack有一个定义良好的消息规范，进程外服务可以用任何语言编写，只要它能够通过 RabbitMQ 进行通信。ZStack Web UI 就是一个很好的例子，它使用 Python 语言编写，通过 RabbitMQ 与 ZStack 进行通信。 ZStack 有一个叫做 canonical event 的机制，它把内部的一些事件暴露出来，例如 VM created, VM stopped, volume created 等等。
  
  ![进程外服务插件](http://zstack.org/images/blogs/scalability/plugin3.png)

- 标签系统

  随着云上面的资源的增长,用户们可能想要有一种可以组合相似资源的高可读性标签的的方法,例如使用 "web-tier-vm" 代表所有 web 服务器的虚拟机。ZStack 中的标签不止能帮助用户对资源进行聚合，而且还能控制软件的行为。ZStack 有一套完整的定义目录、表格和标签用途的规范。除了用户标签也能创建它们自己的标签，可以记录已存在资源的元数据可扩展属性。

  在 ZStack 中，标签上是是包含了与资源相关联的信息片段。主要由以下字段组成：<br/>
    1.uuid: 标签的 UUID<br/>
    2.resourceUuid: 与标签相关联的资源的 UUID<br/>
    3.resourceType: 与标签相关联的资源类型<br/>
    4.tag: 包含有意义的信息字符串<br/>
    5.type: 标签类型，System 或 User<br/>
    ZStack 与其他 IaaS 软件标签的主要不同之处在于：ZStack 把标签分成了两大类：User 和 System。
  
  用户标签：由用户创建，为了对资源进行分组。例如，把安装了 Apache2 HTTP 服务器的虚拟机分组标签标记为"apache2-http"。同一个资源可以与多个标签相关联，根据不同的逻辑进行分组。
  ![User tags](http://zstack.org/images/blogs/scalability/tag1.png)
  与系统标签相配合，用户标签也能用来控制 ZStack 的行为。例如，用户在主存储上创建的 SSD 标签可以被系统标签用来通知 ZStack 在主存储区上创建带有 SSD 标签的虚拟机根卷。
  
  系统标签：它是由 ZStack 的服务和插件预定义的，可用在以下场景。<br/>
  1.元数据: 插件可以使用系统标签来记录资源的元数据。例如 KVM 主机插件保存 OS 版本、libvirt 版本等信息。<br/>
  2.资源属性:插件可以使用系统标签来创建资源的新属性。例如记录数据库中不存在的虚拟机 IP 分类算法字段。根据 ZStack 约定，系统标签形式的属性不应该被用来表示非继承的资源属性；系统标签不是用来弥补拙劣的数据库设计。<br/>
  3.元编程：系统标签也可以用来注释资源去影响 ZStack 的执行流，在某种程度上很像元编程。例如，管理员在 KVM 主机上创建一个系统标签“reservedMemory::1G"，提示 ZStack 主机分配器在那台主机的内存中保留 1G 的内存。<br/>
  4.第三方软件整合：构建在 ZStack 基础上的第三方软件可以使用系统标签来存储 ZStack 数据库中的资源的相关信息，这在避免第三方软件的数据库和 ZStack 的数据库不一致方面尤其有用。

- 瀑布架构

  大多数 IaaS 软件都很少考虑瀑布式的操作，它们或者进行对业务逻辑进行硬编码，或者简单拒绝操作。ZStack 提供的瀑布框架可以把一个资源的操作传播给所有与之相关的资源。例如删除集群时停止运行在其上的虚拟机。在 ZStack 中，资源可以选择通过实现一个简单的扩展点来加入瀑布框架，它能对框架资源的业务逻辑进行解耦。
  ![resources map](http://zstack.org/images/blogs/scalability/cascade1.png)

  正如上图中显示的，资源之间的关系是一个含有闭环的有向图，ZStask 的瀑布架构把它平成树形结构，把闭环拆成分支。例如，删除区域的操作将会形成下面这种结构（部分）：
  ![tree](http://zstack.org/images/blogs/scalability/cascade2.png)

- 工作流引擎

  IaaS 软件中的任务通常都有较长的执行路径，任何步骤中都由可能发生错误。为了保持系统的完整性，IaaS软件必须提供一种能在发生错误时回滚之前执行步骤的机制。有了工作流引擎，ZStack 中个每个步骤都被封装到了一个单独的流中，它能在发生错误时回滚。另外，关键的执行路径也可以由配置文件中的工作流来装配，这就对整个架构进行了进一步解耦。

  ZStack 的工作流为顺序工作流，它由链模式发起并有可预测的执行顺序，它是 ZStack 工作流的基础。工作流步骤由代表整个工作流的 FlowChain 接口来组织。创建 FlowChain 的方法有两种：<br/>
  1.声明的方式：它的步骤可由组件的配置文件来定义。<br/>
  2.编程的方式：通常当一个工作流不是那么重要和步骤不可重用的时候会选择这种方式。
  
------

# 查询 API

  相比与大多数 IaaS 软件采用的点对点查询逻辑的 API，ZStack 使用了一个能自动为每种资源的每个字段生成查询的框架。

------

# Ansible 全自动化

  ZStack 使用 Pyhon 代理来管理 KVM 主机。为了解决大量的设备的安装、升级的难题，ZStack 无缝且透明的整合了 配置管理软件Ansible。通过 Ansible，所有的 ZStack 代理都能自动化的部署、配置和升级。

  所有的 ZStack 代理都包含了3个文件：一个 Python 包(xxx.tar.gz)，一个 init.d 服务文件，一个 Ansible YAML 配置文件。

# 存储和网络

- L2和 L3网络：

  ZStack 把网络模型抽象成 L2 和 L3。L2网络提供了一种 L2 隔离方法,而一个 L3 网络基本上代表了一个与OSI 模型4~7层网络服务相关的子网。ZStack 的整个网络模型就是这样的。
  ![网络架构](http://zstack.org/images/blogs/scalability/network-model1.png)

  L2网络代表了一个真正的L2广播域，它是整个网络的基础。L2网络之上的是 L3网络和网络服务提供者；L3网络是与服务相关联的子网；可以有多个 L3网络工作在同一个 L2网络之下只要它们的 IP 范围没有冲突。一个 L3网络可能拥有多个属于同一子网的 IP，拥有独立的 IP 域是为了允许用户可以保留子网的 IP。

  绑定策略：它允许一个 L2网络从主机分组的集群中绑定/解绑定。

- 虚拟路由网络服务提供者

  在 ZStack 的网络模型中，OSI 模型中的4~7层网络服务来自不同服务提供者的小插件来实现。默认的提供者叫做虚拟路由提供者，使用一个自定义个 Linux VM 作为一个虚拟装置，它可以提供诸如 DHCP、DNS、SNAT、EIP 和每个 L3网络的端口转发。使用虚拟路由器的虚拟机的优势没有单一故障点,对基础设施没有特殊要求,这样用户可以在基础的硬件上实现各种网络服务而无需购买昂贵的设备。

  ZStack 选择使用 NVF 作为实现网络服务的方案。主要考虑如下：<br/>
    1.最小的基础设备需求。用户不必为了迎合 IaaS 软件的网络模型而改变现有的或计划的基础设施<br/>
    2.无单点故障点。<br/>
    3.无状态。遇到未预见的错误时，IaaS 软件可以轻松的销毁的重新创建网络节点<br/>
    4.高可用性。可以部署两个以主从模式使用 Virtual Router Redundancy 协议来工作的虚拟路由来实现高可用。<br/>
    5.Hypervisor 无关的。不依赖 hypervisor 且无缝集成常见的 hypervisor，如 KVM、Xen、VMWare 和 Hyper-V。<br/>
    6.合理的性能。

- 主存储和备份存储

  存储系统根据它的逻辑功能被分成了两种类型，主存储和备份存储。

  主存储以存储虚拟机的卷的存储池的形式工作，它能被运行中的虚拟机访问。这种类型的存储可以是基于文件系统的（把卷存储为文件），也可以是基于块存储的（它的卷的块设备）。它可以是网络共享的存储类型，如 NFS、ISCSI；也可以是本地存储设备，如物理主机的硬盘。
  ![Primary Storage](http://zstack.org/images/blogs/scalability/storage1.png)
  ![Local Storage](http://zstack.org/images/blogs/scalability/storage2.png)

  备份存储作为存放包含操作系统的镜像模板、备份卷和快照的仓库。可以基于文件系统，以文件的形式存储；也可以基于对象形式存储。
  ![Backup Storage](http://zstack.org/images/blogs/scalability/storage3.png)

# 测试

- 集成测试

  集成测试是基于使用模拟器的 JUnit 来构建的。测试用例存放于 ZStack 的 Java 源代码里，开发者可以很容易是使用常规的 JUnit 命令开始测试套件。

- 系统测试

  系统测试是一个叫做 zstack-woodpecker 的独立的 Python 项目，它以 ZStack 的 API 为基础进行构建，可以在真实的、复杂的硬件环境下进行所有的测试，覆盖了函数测试、压力测试和性能测试。

  zstack-woodpecker由3部分构成：<br/>
  1.测试框架：管理所有测试用例,并提供必要的库,工具。<br/>
  2.环境部署工具：可以根据 XML 配置文件来部署环境。<br/>
  3.模块化的测试用例。
  ![zstack-woodpecker](http://zstack.org/images/blogs/testing/test-framework.png)

- 基于模型的测试

  它基于 Model-based Testing，是 zstack-woodpecker 的一个子项目。系统中的测试用例会持续执行随机行为的 API 直到预定义的条件满足或者找到缺陷。作为机器驱动的测试，它能克服人类思维逻辑的缺点来测试那些符合人类逻辑而不是 API 正确的，帮助发现人类不易注意到的边界测试用例。

  工作流：当系统启动时，它根据动作选择策略从一个模块到另一个模块执行动作，每个模块都结束之后，检查器会验证测试结果然后测试出口条件，如果测试失败或出口条件被满足系统则退出，否则它将继续重复测试。
  ![test flow](http://zstack.org/images/blogs/testing/model-based-test.png)

  动作选择策略有3中：<br/>
  1.随机调度程序，简单的随机选择下一个操作，可以设置每个操作的选择权重。<br/>
  2.公平调度程序，每个候选操作都有相等的权重。<br/>
  3.路径覆盖调度程序，它可以根据历史数据来选择下一个操作，形式新的操作路径。
